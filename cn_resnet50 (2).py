# -*- coding: utf-8 -*-
"""CN_ResNet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e9lS0uqmO_dCBzbT8uWkgSC5jBoKejCG
"""

!pip install tensorflow
!pip install seaborn
!pip install matplotlib
!pip install scikit-learn
!pip install keras

import tensorflow as tf
if tf.test.gpu_device_name():
    print('GPU đã được kích hoạt:', tf.test.gpu_device_name())
else:
    print('Không có GPU nào được kích hoạt.')

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
from tensorflow.keras.regularizers import l2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import itertools

# Load CIFAR-10 dataset
cifar10 = tf.keras.datasets.cifar10
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train, y_test = y_train.flatten(), y_test.flatten()

print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)

K = len(set(y_train))
print('Number of Classes:', K)

# Chia dữ liệu thành tập huấn luyện và tập xác thực
train_im, valid_im, train_lab, valid_lab = train_test_split(
    x_train, y_train, test_size=0.20, random_state=40, shuffle=True
)
print("Kích thước dữ liệu huấn luyện sau khi chia:", train_im.shape)
print("Kích thước dữ liệu xác thực:", valid_im.shape)

import seaborn as sns  # Import thư viện Seaborn để vẽ biểu đồ
# Định nghĩa số lượng lớp
num_classes = 10

# Đếm số lượng hình ảnh cho mỗi lớp trong tập huấn luyện và tập kiểm tra
train_counts = [sum(y_train.flatten() == i) for i in range(num_classes)]
test_counts = [sum(y_test.flatten() == i) for i in range(num_classes)]

# Tạo biểu đồ với hai cột
fig, axs = plt.subplots(1, 2, figsize=(12, 4))

# Vẽ biểu đồ phân phối cho tập huấn luyện
sns.barplot(x=list(range(num_classes)), y=train_counts, ax=axs[0],
            palette="muted", legend=False)
axs[0].set_title("Phân phối dữ liệu huấn luyện")
axs[0].set_xlabel("Lớp")
axs[0].set_ylabel("Số lượng")

# Vẽ biểu đồ phân phối cho tập kiểm tra
sns.barplot(x=list(range(num_classes)), y=test_counts, ax=axs[1],
            palette="muted", legend=False)
axs[1].set_title("Phân phối dữ liệu kiểm tra")
axs[1].set_xlabel("Lớp")
axs[1].set_ylabel("Số lượng")

# Hiển thị biểu đồ
plt.tight_layout()
plt.show()

# Định nghĩa khối ResNet
def conv_block(x, filters, kernel_size=(3, 3), stride=1):
    shortcut = x  # Lưu kết nối tắt (shortcut)

    # Lớp tích chập đầu tiên
    x = Conv2D(filters, kernel_size, strides=stride, padding='same', kernel_regularizer=l2(0.001))(x)
    x = BatchNormalization()(x)  # Chuẩn hóa theo batch
    x = Activation('relu')(x)  # Kích hoạt ReLU

    # Lớp tích chập thứ hai
    x = Conv2D(filters, kernel_size, padding='same', kernel_regularizer=l2(0.001))(x)
    x = BatchNormalization()(x)  # Chuẩn hóa theo batch

    # Điều chỉnh shortcut nếu kích thước không khớp
    if stride != 1:
        shortcut = Conv2D(filters, kernel_size=(1, 1), strides=stride, kernel_regularizer=l2(0.001))(shortcut)
        shortcut = BatchNormalization()(shortcut)

    # Kết hợp shortcut với đầu ra qua phép cộng
    x = Add()([x, shortcut])

    return x # Return the output tensor of the conv_block

# Định nghĩa mô hình ResNet50
# Cập nhật mô hình với sơ đồ mới
# Bổ sung Global Avg Pooling, Dropout, và lớp Fully Connected

def resnet50(input_shape=(32, 32, 3), num_classes=10):
    inputs = Input(shape=input_shape)  # Lớp đầu vào

    # Conv1
    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(inputs)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)

    # Conv2_x
    for _ in range(3):
        x = conv_block(x, 64)

    # Conv3_x
    for _ in range(4):
        x = conv_block(x, 128, stride=2 if _ == 0 else 1)

    # Conv4_x
    for _ in range(6):
        x = conv_block(x, 256, stride=2 if _ == 0 else 1)

    # Conv5_x
    for _ in range(3):
        x = conv_block(x, 512, stride=2 if _ == 0 else 1)

    # Global Avg Pooling và Fully Connected
    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.5)(x)
    outputs = Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(x)

    model = Model(inputs, outputs, name='ResNet50_CIFAR10')
    return model

# Compile và sử dụng sơ đồ callback hợp lý
print("Sơ đồ đã được cập nhật để khớp hoàn toàn với hình vẽ.")

print("Number of classes (K):", K)

# Biên dịch mô hình với tối ưu hóa và tốc độ học tốt hơn
model = resnet50(input_shape=(32, 32, 3), num_classes=K)
model.compile(
    optimizer=Adam(learning_rate=0.0005),  # Sử dụng Adam với tốc độ học nhỏ hơn
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Import thư viện tăng cường dữ liệu
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Tăng cường dữ liệu
data_generator = ImageDataGenerator(
    width_shift_range=0.2,  # Dịch chuyển ngang
    height_shift_range=0.2,  # Dịch chuyển dọc
    horizontal_flip=True,  # Lật ngang
    rotation_range=15  # Xoay nhẹ
)
data_generator.fit(train_im)
train_generator = data_generator.flow(train_im, train_lab, batch_size=128)

# Các callback
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,         # Giảm learning rate còn 50%
    patience=3,         # Chờ 3 epoch trước khi giảm
    min_lr=1e-6         # Learning rate nhỏ nhất
)
checkpoint = ModelCheckpoint(
    'resnet50_cifar10_best.keras',  # Đường dẫn để lưu mô hình tốt nhất
    monitor='val_accuracy',        # Theo dõi độ chính xác trên tập xác thực
    save_best_only=True            # Chỉ lưu mô hình nếu độ chính xác cải thiện
)
early_stopping = EarlyStopping(
    monitor='val_loss',            # Theo dõi giá trị mất mát trên tập xác thực
    patience=8,                   # Dừng huấn luyện nếu không cải thiện trong 10 epoch
    restore_best_weights=True      # Khôi phục trọng số tốt nhất sau khi dừng
)

# Tạo generator cho dữ liệu huấn luyện
train_generator = data_generator.flow(
    train_im, train_lab, batch_size=128  # Batch size là 128
)

# Huấn luyện mô hình
steps_per_epoch = train_im.shape[0] // 128  # Số bước mỗi epoch, tính dựa trên batch size là 128
r = model.fit(
    train_generator,                      # Generator dữ liệu huấn luyện
    validation_data=(valid_im, valid_lab), # Dữ liệu xác thực (hình ảnh và nhãn)
    steps_per_epoch=steps_per_epoch,      # Số bước mỗi epoch
    epochs=100,                           # Số lượng epoch để huấn luyện
    callbacks=[reduce_lr, checkpoint, early_stopping]  # Danh sách các callback
)

# Tải mô hình tốt nhất đã được lưu
best_model = tf.keras.models.load_model('resnet50_cifar10_best.keras')
eval_results = best_model.evaluate(x_test, y_test)
print(f"Test Loss: {eval_results[0]}")
print(f"Test Accuracy: {eval_results[1]}")

# Hiển thị hình ảnh gốc và hình ảnh đã tăng cường
# Lấy mẫu các hình ảnh gốc từ train_im
num_samples = 5  # Số lượng hình ảnh cần hiển thị
indices = np.random.choice(range(train_im.shape[0]), num_samples, replace=False)

fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))

# Hiển thị hình ảnh gốc
for i, idx in enumerate(indices):
    axes[0, i].imshow(train_im[idx])
    axes[0, i].axis('off')
    axes[0, i].set_title("Hình ảnh gốc")

augmented_images = [data_generator.random_transform(train_im[idx]) for idx in indices]

# Hiển thị hình ảnh đã tăng cường
for i, img in enumerate(augmented_images):
    axes[1, i].imshow(img)
    axes[1, i].axis('off')
    axes[1, i].set_title("Hình ảnh đã tăng cường")

plt.tight_layout()
plt.show()

# Plot Training History
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(r.history['accuracy'], label='Train Accuracy')
plt.plot(r.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Accuracy')

plt.subplot(1, 2, 2)
plt.plot(r.history['loss'], label='Train Loss')
plt.plot(r.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss')
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Dự đoán đầu ra của mô hình
predictions = model.predict(x_test)
# Định nghĩa lại các nhãn cho các lớp trong CIFAR-10
labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

# Tính toán nhãn dự đoán
Y_pred_classes = np.argmax(predictions, axis=1)  # Lấy nhãn có xác suất cao nhất từ đầu ra của mô hình

# Tính toán ma trận nhầm lẫn
cm = confusion_matrix(y_test, Y_pred_classes)

# Chuẩn hóa ma trận nhầm lẫn
cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

# Tạo biểu đồ heatmap
plt.figure(figsize=(12, 12))
sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues', xticklabels=labels, yticklabels=labels)

# Đặt tiêu đề và nhãn trục
plt.title('Ma trận nhầm lẫn đã chuẩn hóa', fontsize=16)  # Tiêu đề
plt.xlabel('Nhãn dự đoán', fontsize=14)                 # Nhãn trục x
plt.ylabel('Nhãn thực tế', fontsize=14)                 # Nhãn trục y
plt.show()

# Predictions and Visualization
R = 5
C = 5
fig, axes = plt.subplots(R, C, figsize=(12, 12))
axes = axes.ravel()

for i in np.arange(0, R * C):
    idx = np.random.randint(0, x_test.shape[0])
    confidence = predictions[idx][np.argmax(predictions[idx])]
    axes[i].imshow(x_test[idx])
    axes[i].set_title("Nhãn thật: %s \nPred: %s \n Dự đoán: %.2f" % (
        labels[y_test[idx]],
        labels[np.argmax(predictions[idx])],
        confidence
    ))
    axes[i].axis('off')

plt.subplots_adjust(wspace=1)
plt.show()

# Hiển thị các lỗi quan trọng nhất
def display_errors(errors_index, img_errors, pred_errors, obs_errors, pred_probs):
    """ Hiển thị 10 hình ảnh cùng với nhãn thực (real labels), nhãn dự đoán (predicted labels), và xác suất dự đoán. """
    n = 0
    nrows = 2  # Số hàng
    ncols = 5  # Số cột
    fig, ax = plt.subplots(nrows, ncols, sharex=True, sharey=True, figsize=(12, 6))

    for row in range(nrows):  # Duyệt qua từng hàng
        for col in range(ncols):  # Duyệt qua từng cột
            error = errors_index[n]  # Lấy chỉ số của lỗi
            ax[row, col].imshow(img_errors[error])  # Hiển thị hình ảnh lỗi

            # Xác suất dự đoán cho lớp dự đoán
            confidence = pred_probs[error]

            ax[row, col].set_title("Lớp: {}\n Nhãn thật: {}\n Dự đoán: {:.2f}".format(
                labels[pred_errors[error]],  # Lớp được dự đoán
                labels[obs_errors[error]],  # Nhãn thật
                confidence                  # Xác suất dự đoán
            ))
            n += 1  # Tăng chỉ số lỗi
            ax[row, col].axis('off')  # Tắt hiển thị trục
            plt.subplots_adjust(wspace=1)  # Điều chỉnh khoảng cách giữa các ô

# Tính toán xác suất và các lỗi
Y_pred_classes = np.argmax(predictions, axis=1)  # Lấy nhãn dự đoán
Y_pred_probs = np.max(predictions, axis=1)       # Lấy xác suất cao nhất cho nhãn dự đoán
errors = (Y_pred_classes != y_test)             # Xác định các lỗi
error_indices = np.where(errors)[0]             # Lấy các chỉ số của lỗi

# Sắp xếp lỗi dựa trên độ tự tin của dự đoán
sorted_errors = np.argsort(Y_pred_probs[errors])  # Lỗi được sắp xếp theo xác suất dự đoán

# Hiển thị 10 lỗi quan trọng nhất
most_important_errors = sorted_errors[-10:]      # Lấy 10 lỗi cuối cùng (quan trọng nhất)
X_test_errors = x_test[error_indices]            # Hình ảnh trong tập kiểm tra có lỗi
Y_pred_classes_errors = Y_pred_classes[error_indices]  # Nhãn dự đoán cho các lỗi
Y_true_errors = y_test[error_indices]            # Nhãn thật cho các lỗi

# Hiển thị các lỗi quan trọng nhất
display_errors(most_important_errors, X_test_errors, Y_pred_classes_errors, Y_true_errors, Y_pred_probs[errors])

# Kiểm tra các mẫu cụ thể
def show_test(number):
    fig = plt.figure(figsize=(3, 3))  # Tạo khung hiển thị với kích thước 3x3

    # Lấy một hình ảnh từ tập kiểm tra và mở rộng chiều để khớp với đầu vào của mô hình
    test_image = np.expand_dims(x_test[number], axis=0)

    # Dự đoán xác suất các lớp
    test_result = model.predict(test_image)
    dict_key = np.argmax(test_result, axis=1)[0]  # Lấy chỉ số của lớp được dự đoán
    confidence = test_result[0][dict_key]  # Lấy độ tự tin của dự đoán

    # Hiển thị hình ảnh và thông tin dự đoán
    plt.imshow(x_test[number])
    plt.title("Dự đoán: {} \nNhãn thật: {} \nĐộ tự tin: {:.2f}%".format(
        labels[dict_key],       # Tên lớp được dự đoán
        labels[y_test[number]], # Tên lớp thực tế
        confidence * 100        # Độ tự tin của dự đoán (đổi sang phần trăm)
    ))
    plt.axis('off')  # Tắt hiển thị trục
    plt.show()

# Kiểm tra một ví dụ cụ thể
show_test(1)  # Thay số `1` bằng chỉ số mẫu bạn muốn kiểm tra

import os

# Lưu và đánh giá mô hình
save_dir = os.path.join(os.getcwd(), 'saved_models')  # Thư mục để lưu mô hình
model_name = 'resnet50_cifar10_trained_model.keras'   # Tên tệp mô hình

# Tạo thư mục nếu nó chưa tồn tại
if not os.path.isdir(save_dir):
    os.makedirs(save_dir)

# Đường dẫn đầy đủ để lưu mô hình
model_path = os.path.join(save_dir, model_name)

# Lưu mô hình vào tệp .keras
model.save(model_path)
print('Đã lưu mô hình đã huấn luyện tại %s ' % model_path)

# Đánh giá mô hình trên tập kiểm tra
scores = model.evaluate(x_test, y_test, verbose=1)  # Đánh giá trên tập kiểm tra
print('Mất mát trên tập kiểm tra (Test loss):', scores[0])   # In giá trị mất mát
print('Độ chính xác trên tập kiểm tra (Test accuracy):', scores[1])  # In độ chính xác

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import numpy as np
import os
from google.colab import files

# Tải mô hình đã lưu
model_path = os.path.join('saved_models', 'resnet50_cifar10_trained_model.keras')  # Đường dẫn đến mô hình ResNet50
model = load_model(model_path)
print("Mô hình ResNet50 đã được tải thành công!")

# Nhãn cho các lớp của tập dữ liệu CIFAR-10
labels = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']

def predict_uploaded_image(img_path, top_k=3):
    """
    Hàm dự đoán nhãn của ảnh được tải lên
    """
    # Tiền xử lý ảnh
    img = image.load_img(img_path, target_size=(32, 32))  # Resize ảnh về 32x32
    img_array = image.img_to_array(img)  # Chuyển đổi ảnh thành mảng numpy
    img_array = np.expand_dims(img_array, axis=0)  # Mở rộng chiều để phù hợp với đầu vào mô hình
    img_array = img_array / 255.0  # Chuẩn hóa ảnh (phù hợp với mô hình đã huấn luyện)

    # Dự đoán
    predictions = model.predict(img_array)[0]  # Dự đoán xác suất của các lớp
    predicted_classes = np.argsort(predictions)[::-1][:top_k]  # Lấy top-k lớp có xác suất cao nhất

    # Hiển thị kết quả
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Dự đoán: {labels[predicted_classes[0]]}")
    plt.show()

    print(f"Xác suất dự đoán:")
    for i, pred_class in enumerate(predicted_classes):
        print(f"Top {i+1}: {labels[pred_class]} với xác suất {predictions[pred_class]:.2f}")

# Tải ảnh lên từ thiết bị
uploaded = files.upload()
for img_name in uploaded.keys():
    print(f"Đang dự đoán cho ảnh: {img_name}")
    predict_uploaded_image(img_name, top_k=3)  # Hiển thị top-3 dự đoán

def predict_image(model, image_path):
    from tensorflow.keras.preprocessing.image import load_img, img_to_array
    from PIL import Image

    # Load và tiền xử lý ảnh
    original_image = load_img(image_path)  # Load ảnh gốc
    img_array = img_to_array(original_image.resize((32, 32)))  # Resize ảnh về 32x32
    img_array = np.expand_dims(img_array, axis=0)  # Thêm chiều batch
    img_array = img_array / 255.0  # Chuẩn hóa ảnh

    # Dự đoán
    predictions = model.predict(img_array)
    predicted_index = np.argmax(predictions, axis=1)[0]
    processed_size = (32, 32)
    predicted_class = labels[predicted_index]

    return original_image, processed_size, predicted_index, predicted_class

def on_file_upload(change):
    uploaded_file = next(iter(change['new'].values()))  # Lấy file ảnh tải lên
    image_path = uploaded_file['metadata']['name']
    with open(image_path, 'wb') as f:
        f.write(uploaded_file['content'])  # Lưu file ảnh

    # Hiển thị trạng thái "Đang tiến hành dự đoán..."
    loading_label.value = "<p style='font-size: 18px; color: #ff5722; font-weight: bold; text-align: center;'>Đang tiến hành dự đoán...</p>"

    # Dự đoán kết quả
    original_image, processed_size, predicted_index, predicted_class = predict_image(model, image_path)

    # Chuyển ảnh gốc sang Base64 để hiển thị
    buffer_input = BytesIO()
    original_image.save(buffer_input, format="PNG")
    img_base64_input = base64.b64encode(buffer_input.getvalue()).decode("utf-8")

    # Hiển thị kết quả
    with output_widget:
        output_widget.clear_output()
        display(widgets.HTML(value=f"""
        <div style='
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            border: 2px solid #1976d2;
            border-radius: 12px;
            padding: 20px;
            max-width: 600px;
            margin: 20px auto;
            background-color: #f5f5f5;'>

            <h2 style='color: #1976d2; font-size: 20px; text-align:center; margin-bottom: 15px;'>Kết quả Dự Đoán</h2>
            <p style='font-size: 16px; color: #333333; margin-bottom: 10px;'><b>Tên file ảnh:</b> {uploaded_file['metadata']['name']}</p>
            <p style='font-size: 16px; color: #333333; margin-bottom: 10px;'><b>Kích thước gốc:</b> {original_image.size}</p>
            <p style='font-size: 16px; color: #333333; margin-bottom: 10px;'><b>Kích thước sau chuẩn hóa:</b> {processed_size}</p>
            <p style='font-size: 16px; color: #333333; margin-bottom: 20px;'><b>Lớp dự đoán:</b> <span style='color:#d32f2f; font-weight:bold;'>{predicted_class}</span></p>

            <div style="display: flex; justify-content: center; align-items: center; margin-top: 15px;">
                <div style="text-align: center;">
                    <p style="font-size: 16px; font-weight: bold; color: #1976d2; margin-bottom: 10px;">Ảnh đầu vào</p>
                    <img src="data:image/png;base64,{img_base64_input}" alt="Ảnh đầu vào" style="max-width: 200px; max-height: 200px; border-radius: 8px; border: 2px solid #ccc;"/>
                </div>
            </div>
        </div>
        """))

    # Ẩn thông báo "Đang tiến hành dự đoán..."
    loading_label.value = ""

import ipywidgets as widgets
from IPython.display import display
from io import BytesIO
import base64

# Nút tải ảnh
upload_button = widgets.FileUpload(accept='image/*', multiple=False, description="Tải lên")
upload_button.observe(on_file_upload, names='value')

# Tạo nhãn trạng thái tải
loading_label = widgets.HTML(value="", layout=widgets.Layout(margin="10px 0"))

# Tạo widget để hiển thị kết quả
output_widget = widgets.Output()

# Giao diện chính
interface = widgets.VBox([
    widgets.HTML(value="<h3 style='color: #1565c0; font-size: 16px; text-align:center; padding: 10px;'>Tải lên hình ảnh muốn dự đoán:</h3>"),
    widgets.HBox([upload_button], layout=widgets.Layout(justify_content='center', margin='0 0 20px 0')),
    loading_label,  # Biến loading_label để hiển thị trạng thái
    output_widget
])

# Hiển thị giao diện
display(interface)